# üìß Clasificaci√≥n de Correos SPAM con √Årbol de Decisi√≥n

Este proyecto implementa un modelo de **aprendizaje supervisado** utilizando un **√Årbol de Decisi√≥n** para clasificar correos electr√≥nicos como **SPAM o NO-SPAM**, apoyado en las librer√≠as de *scikit-learn* y una interfaz interactiva creada con **Streamlit**.

---

## üöÄ Objetivo

Evaluar el rendimiento de un modelo de **Decision Tree** aplicado a un conjunto de correos electr√≥nicos, midiendo su **exactitud**, **F1-score** y **Z-score** a lo largo de m√∫ltiples ejecuciones.  
El prop√≥sito es analizar la **precisi√≥n y estabilidad** del clasificador frente a diferentes divisiones de los datos.

---

## üß© Estructura del proyecto

```bash
spam_decisiontree.py   # Script principal con Streamlit
emails__dataset.csv    # Dataset con los correos (Body, Sender, BodyLength, Spam)
README.md              # Documento actual
```

---

## üß† Tecnolog√≠as utilizadas

- **Python 3.10+**
- **scikit-learn** ‚Äì Entrenamiento y evaluaci√≥n del modelo
- **pandas / numpy** ‚Äì Manipulaci√≥n y an√°lisis de datos
- **matplotlib** ‚Äì Visualizaci√≥n de resultados
- **Streamlit** ‚Äì Interfaz web interactiva
- **SciPy** ‚Äì C√°lculo de Z-score y manejo de matrices dispersas

---

## üìä Descripci√≥n del dataset

El conjunto de datos contiene informaci√≥n de correos electr√≥nicos con las siguientes columnas:

| Variable | Descripci√≥n |
|-----------|-------------|
| `Body` | Texto del mensaje del correo |
| `Sender` | Remitente del correo |
| `BodyLength` | Longitud del cuerpo del mensaje (opcional) |
| `Spam` | Variable objetivo (1 = SPAM, 0 = NO-SPAM) |

---

## ‚öôÔ∏è Flujo del programa

### **1. Configuraci√≥n general**
El usuario define los par√°metros de ejecuci√≥n desde la barra lateral de Streamlit:
- N√∫mero de ejecuciones (`num_runs`)
- Tama√±o del conjunto de prueba (`test_size`)
- Profundidad m√°xima del √°rbol (`max_depth`)

### **2. Carga de datos**
Se lee el archivo `emails__dataset.csv` y se muestra una vista previa del contenido.

### **3. Preprocesamiento de variables**

- **Vectorizaci√≥n del texto:**  
  Se aplica `TfidfVectorizer(stop_words="english", max_features=500)` para transformar el texto del cuerpo de los correos en vectores num√©ricos.  
  Esto permite representar los mensajes seg√∫n las palabras m√°s relevantes, eliminando palabras comunes en ingl√©s.

- **Codificaci√≥n del remitente:**  
  Se usa `LabelEncoder` para transformar el nombre del remitente en n√∫meros.  
  Este m√©todo se eligi√≥ por ser **m√°s eficiente** que `OneHotEncoder`, ya que evita crear una matriz enorme con miles de columnas.  
  Adem√°s, el modelo solo necesita distinguir entre remitentes, no establecer relaciones entre ellos.

- **Incorporaci√≥n de la longitud del cuerpo:**  
  Si la columna `BodyLength` est√° presente, se incluye como caracter√≠stica adicional.  
  Se utiliza `hstack` para **unir todas las matrices (texto, remitente y longitud)** en una sola matriz `X`.  
  Esto facilita el entrenamiento del modelo, ya que todas las variables quedan integradas en una sola estructura.

### **4. Entrenamiento y evaluaci√≥n del modelo**

En cada ejecuci√≥n:
1. Se dividen los datos en entrenamiento y prueba.  
2. Se entrena un modelo de **√Årbol de Decisi√≥n** con la profundidad elegida.  
3. Se calculan las m√©tricas de desempe√±o:
   - **Accuracy:** mide la proporci√≥n de aciertos.  
   - **F1-score:** combina precisi√≥n y recall, √∫til cuando las clases est√°n desbalanceadas.  
   - **Z-score:** detecta ejecuciones con resultados at√≠picos o inconsistentes.

### **5. Resultados y estad√≠sticas**

Se muestra una tabla con las m√©tricas de cada ejecuci√≥n y un resumen estad√≠stico global (`describe()`), que incluye media, desviaci√≥n est√°ndar, valores m√≠nimos y m√°ximos.

### **6. Visualizaci√≥n**

Se genera un gr√°fico de l√≠neas donde se observa c√≥mo var√≠a la **exactitud** a trav√©s de las ejecuciones, junto con una l√≠nea roja punteada que representa el promedio general.

### **7. Conclusiones autom√°ticas**

El script calcula la **media y desviaci√≥n est√°ndar** de la exactitud y genera conclusiones autom√°ticas sobre la estabilidad y el rendimiento del modelo.

---

## üìà Resultados generales

- **Exactitud promedio:** ‚âà 80%  
- **Desviaci√≥n est√°ndar:** muestra variaciones leves entre ejecuciones.  
- **F1-score:** refleja un buen balance entre precisi√≥n y recall.  
- **Z-score:** permite detectar ejecuciones con resultados at√≠picos.

El modelo demostr√≥ ser confiable y f√°cil de interpretar, aunque sensible a los cambios en la partici√≥n de los datos.

---

## üí¨ Discusi√≥n

El **√Årbol de Decisi√≥n** es un modelo sencillo y explicativo, ideal para comprender c√≥mo se comportan los datos.  
Sin embargo, puede **sobreajustarse** si su profundidad no se controla adecuadamente.  
Para mejorar la precisi√≥n y estabilidad, podr√≠an usarse modelos m√°s avanzados como:

- **Random Forest:** genera muchos √°rboles de decisi√≥n y combina sus resultados para reducir el sobreajuste y mejorar la estabilidad.  
- **Gradient Boosting:** construye los √°rboles de forma secuencial, corrigiendo los errores de los anteriores. Es m√°s preciso, aunque tambi√©n m√°s exigente en c√≥mputo.

---

## üß© Conclusiones

- El modelo logr√≥ una precisi√≥n media del **80%**, lo que se considera aceptable para un conjunto de datos de texto sin procesamiento ling√º√≠stico avanzado.  
- Se observ√≥ **ligera variabilidad**, por lo que es recomendable ejecutar el modelo varias veces para validar su estabilidad.  
- Este proyecto sirve como **base s√≥lida** para implementar t√©cnicas m√°s robustas de clasificaci√≥n de texto, como Random Forest o Gradient Boosting.

---

## üåê Despliegue y c√≥digo fuente

- **Repositorio:** [https://github.com/disdesoft/decisiontree](https://github.com/disdesoft/decisiontree)  
- **Aplicaci√≥n en l√≠nea (Streamlit):** [https://arboldedecision.streamlit.app/](https://arboldedecision.streamlit.app/)
